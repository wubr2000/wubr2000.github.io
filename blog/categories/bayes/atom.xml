<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Bayes | Codex]]></title>
  <link href="http://wubr2000.github.io/blog/categories/bayes/atom.xml" rel="self"/>
  <link href="http://wubr2000.github.io/"/>
  <updated>2014-05-29T00:28:29-07:00</updated>
  <id>http://wubr2000.github.io/</id>
  <author>
    <name><![CDATA[Bruno Wu]]></name>
    <email><![CDATA[wubr2000@hotmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Bayesian Invasion]]></title>
    <link href="http://wubr2000.github.io/blog/2014/05/27/bayesian-invasion/"/>
    <updated>2014-05-27T22:53:07-07:00</updated>
    <id>http://wubr2000.github.io/blog/2014/05/27/bayesian-invasion</id>
    <content type="html"><![CDATA[<blockquote>
  <p>Methods can be abused and that is true with any approach, including Bayesian but it offers a more coherent, philosophical way in which to look at the world 
- Nate Silver</p>
</blockquote>

<p>Problems with MLE:</p>

<ol>
  <li>
    <p>MLE does poorly when the sample size is small. In particular, the ML estimator can be biased.</p>
  </li>
  <li>
    <p>If the coin is tossed once, and came up heads, ML estimation would estimate p = 1.</p>
  </li>
  <li>
    <p>Also, ML assumes uniform priors, which is often incorrect. We frequently have very specific information regarding the plausibility of various hypotheses (e.g., refer the simplest hypothesis etc).</p>
  </li>
</ol>

<p>We want to prove the following statement:</p>

<table>
  <tbody>
    <tr>
      <td>$\displaystyle\frac{1}{</td>
      <td>C_k</td>
      <td>}\sum<em>{i,i&rsquo;\in C_k}\sum</em>{j=1}^{p}(x<em>{ij} - x</em>{i&rsquo;j})^2 = 2\sum<em>{i\in C_k}\sum</em>{j=1}^{p}(x<em>{ij} - \bar{x}</em>{kj})^2$</td>
    </tr>
  </tbody>
</table>

<p>To adress these problems, we turn to the framework of Bayesian estimation.</p>

<!-- more -->

]]></content>
  </entry>
  
</feed>
