<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Machine | Codex]]></title>
  <link href="http://wubr2000.github.io/blog/categories/machine/atom.xml" rel="self"/>
  <link href="http://wubr2000.github.io/"/>
  <updated>2014-06-23T00:18:34-07:00</updated>
  <id>http://wubr2000.github.io/</id>
  <author>
    <name><![CDATA[Bruno Wu]]></name>
    <email><![CDATA[wubr2000@hotmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[To Grow a (Decision) Tree]]></title>
    <link href="http://wubr2000.github.io/blog/2014/06/07/grow-tree/"/>
    <updated>2014-06-07T23:48:33-07:00</updated>
    <id>http://wubr2000.github.io/blog/2014/06/07/grow-tree</id>
    <content type="html"><![CDATA[<p>During the fourth week at Zipfian, we implemented a few more basic machine learning algorithms from scratch using Python. One of the more interesting ones for me is the <em>decision tree</em>. As a classification technique, the decision tree has quite a number of appealing features, the chief of which are its simplicity and interpretability. Despite its conceptual simplicity, it is actually not that straightforward to implement from a programming perspective. Hopefully, this post can serve as a brief overview on how to program a simple decision tree. </p>

<p>Like many other algorithms we&rsquo;ve learned, the first step is to define a <em>cost function</em> that we will be minimizing. In the case of a decision tree, the cost function determines how variance is calculated at each branch of the tree. For our implementation, we used a concept called <em>entropy</em> to calculate this variance:</p>

<script type="math/tex; mode=display">H(y) =  -\displaystyle \sum_{i=1}^{m} P(c_i)\log_2(P(c_i))</script>

<!-- more -->

<p>In general, entropy measures the amount of <strong>disorder</strong> in a set and our goal is <strong>minimize entropy</strong> after each split. Given the mathematical definition of entropy above, here is one way to write the <code>entropy</code> function in Python:</p>

<p>```python
import pandas as pd
import numpy as np
import math</p>

<p>def entropy(y):
    &lsquo;&rsquo;&rsquo;
    INPUT: NUMPY ARRAY
    OUTPUT: FLOAT</p>

<pre><code>Return the entropy of the array y.
'''
total = 0
for cl in np.unique(y):
    prob = np.sum(y == cl) / float(len(y))
    total += prob * math.log(prob)
return -total ```
</code></pre>

<p>In the code above, we first calculate the variable <code>prob</code> which gives the probability of occurence for each class/label in a set. Then we plug this probability into the entropy formula to derive the total entropy for the set.</p>

<p>Now that we have a general function for calculating entropy, we can think about how to use it to determine the best split. Below is the pseudocode from our assignment which provides a roadmap on how to implement a decision tree:</p>

<p><code>python
'''
function BuildTree:
    If every item in the dataset is in the same class
    or there is no feature left to split the data:
        return a leaf node with the class label
    Else:
        find the best feature and value to split the data 
        split the dataset
        create a node
        for each split
            call BuildTree and add the result as a child of the node
        return node
'''
</code></p>

<p>As can be seen from this pseudocode, an important step within this <code>BuildTree</code> function is to &ldquo;find the best feature and value to split the data&rdquo;. At this point, we were introduced to a critical concept called <em>information gain</em> which determines how we should judge the &ldquo;effectiveness&rdquo; of a particular split.</p>

<script type="math/tex; mode=display">Gain(S,D) =  H(S) - \displaystyle \sum_{V\in D} \frac{\lvert V\rvert}{\lvert S\rvert}H(V)</script>

<p><script type="math/tex">D</script> comprises the &ldquo;children&rdquo; sets from the original parent set (i.e. pre-split set) of <script type="math/tex">S</script> while <script type="math/tex">V</script> represents an individual child branch. In our case, since we&rsquo;re only dealing with binary splits, we only have two children branches <script type="math/tex">(A,B)</script> in <script type="math/tex">D</script>. The <em>information gain</em> for each split is calculated as follows:</p>

<script type="math/tex; mode=display">Gain(S,A,B) =  H(S) - \displaystyle \frac{\lvert A\rvert}{\lvert S\rvert}H(A) - \displaystyle \frac{\lvert B\rvert}{\lvert S\rvert}H(B)</script>

<p>where <script type="math/tex">S = A \cup B</script> Here, we&rsquo;ve finally encountered our <em>splitting criteria</em>. <script type="math/tex">H(S)</script> is the entropy of the parent branch <script type="math/tex">S</script>, while <script type="math/tex">H(A)</script> and <script type="math/tex">H(B)</script> are the entropy of child branch <script type="math/tex">A</script> and child branch <script type="math/tex">B</script>, respectively. </p>

<blockquote>
  <p>In short, this formula says that the information gain of a split is equal to the difference between the entropy of the parent branch (before the split) and the combined entropy the children branches (after the split). </p>
</blockquote>

<p>The lower the entropy of the combined children branches, the higher the information gain. So the <strong>best split</strong> at any node is the one that results in the lowest combined entropy of the children branches (therefore, the highest information gain).</p>

<p>[Talk about recursion next]</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Gradient Descent the Python Way]]></title>
    <link href="http://wubr2000.github.io/blog/2014/05/27/bayesian-invasion/"/>
    <updated>2014-05-27T22:53:07-07:00</updated>
    <id>http://wubr2000.github.io/blog/2014/05/27/bayesian-invasion</id>
    <content type="html"><![CDATA[<p>During our third week at Zipfian, we implemented the linear regression model by using various Python libraries (e.g. <code>statsmodel</code> and <code>scikit-learn</code>). We also coded the normal equation (<script type="math/tex">\beta = (X^TX)^{-1}X^TY</script>) directly as a Python function. In addition to using standard library functions to perform linear regressions, we also implemented an optimization technique called <strong><a href="http://en.wikipedia.org/wiki/Gradient_descent">gradient descent</a></strong> to approximate the analytical solution for deriving the coefficients of a linear regression. When a matrix is non-invertible, one would have to use gradient descent to arrive at the coefficients of a linear regression since a <a href="http://stats.stackexchange.com/questions/69442/linear-regression-and-non-invertibility">unique solution does not exist</a> in this case. In fact, gradient descent is a general optimization technique for finding the local minimum of a function and as such, can be applied to many other machine learning situations where an analytical solution is either too cumbersome or is infeasible. So I thought it&rsquo;d be quite useful to get a better handle on this important tool.</p>

<p>Here&rsquo;s the general gradient descent algorithm:</p>

<script type="math/tex; mode=display">
\begin{align*}
  \theta_{j+1} = \theta_j - \alpha \frac{\partial}{\partial\theta_j} J(\theta)
\end{align*}
</script>

<p>where <script type="math/tex">J(\theta)</script> is a function that we want to minimize and <script type="math/tex">\alpha</script> is the <em>learning rate</em>.</p>

<!-- more -->

<p>There is a <a href="https://class.coursera.org/ml-003/lecture/10">video</a> by Andrew Ng of Stanford on the basic intuition behind gradient descent. </p>

<blockquote>
  <p>The general idea of gradient descent is that we take the gradient (i.e. slope or first-derivation) of the function we want to minimize at some starting point. Then we take one step in the <strong>negative direction</strong> of the gradient (hence, a descent) and repeat this process many times. Eventually, the algorithm will converge to a point where the gradient is zero and where the function is, therefore, at a local minimum. The <script type="math/tex">\alpha</script> (or the learning rate) of the gradient descent algorithm determines how big a step we take at each iteration.</p>
</blockquote>

<p>For the case of linear regression, the function we want to minimize is the RSS (or the cost function):</p>

<script type="math/tex; mode=display">
\begin{align*}
  RSS = \displaystyle \sum_{i=1}^{n} (y_i - f(x_i))^2
\end{align*}
</script>

<p>By plugging the RSS (as <script type="math/tex">J(\theta)</script>) into the general gradient descent algorithm and doing some math (as explained on pages 4 and 5 of Andrew Ng&rsquo;s lecture notes <a href="http://cs229.stanford.edu/notes/cs229-notes1.pdf">here</a>), we arrive at the following:</p>

<script type="math/tex; mode=display">
\begin{align*}
  \theta_{j+1} = \theta_j - \alpha \frac{1}{m} \displaystyle \sum_{i=1}^{m}(h_{\theta}(x^{(i)}) - y^{(i)}))x_j^{(i)}
\end{align*}
</script>

<p>where <script type="math/tex">h_{\theta}(x^{(i)})</script> is the predicted value (<script type="math/tex">\hat{y}</script>) of <script type="math/tex">x^{(i)}</script> and <script type="math/tex">y^{(i)}</script> is the true <script type="math/tex">y</script> value.</p>

<p>Once we have tailored the gradient descent algorithm for linear regression, the Python implementation of the coefficient <code>update</code> function is not too difficult. We just need to make sure that the matrix multiplications are done properly:</p>

<p><code>python
def update(self, X, y, alpha):
  gradient = X.T.dot(X.dot(self.coeffs)-y)
  m = len(y)
  return self.coeffs - alpha * gradient / m
</code></p>

<p>Next, we create a <code>run</code> function to iterate through the above gradient descent <code>update</code> function in order to arrive at a set of coefficient vector that would minimize the RSS for the linear regression. To do this, we need to pass in <script type="math/tex">\alpha</script> to control how <em>large</em> a step we&rsquo;d want to take from one iteration to the next:</p>

<p><code>python
def run(self, X, y, alpha=0.01, num_iterations=10000):
  for i in xrange(num_iterations):
    self.coeffs = self.update(X,y,alpha)
</code></p>

<p>Finally, we can use this set of coefficients vector for our linear regression (<script type="math/tex">\hat{y} = \beta X</script>):</p>

<p><code>python
def predict(self, X):
  return X.dot(self.coeffs)
</code></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Solving the Monty Hall Problem Using Monte Carlo Simulation]]></title>
    <link href="http://wubr2000.github.io/blog/2013/12/29/monty-hall-simulation/"/>
    <updated>2013-12-29T19:25:09-08:00</updated>
    <id>http://wubr2000.github.io/blog/2013/12/29/monty-hall-simulation</id>
    <content type="html"><![CDATA[<p>This exercise is from <a href="http://cs109.org/">Harvard&rsquo;s CS109 course.</a></p>

<p>In the Monty Hall game show, contestants try to guess which of 3 closed doors contain a cash prize (goats are behind the other two doors). Of course, the odds of choosing the correct door are 1 in 3. As a twist, the host of the show occasionally opens a door after a contestant makes his or her choice. This door is always one of the two the contestant did not pick, and is also always one of the goat doors (note that it is always possible to do this, since there are two goat doors). At this point, the contestant has the option of keeping his or her original choice, or swtiching to the other unopened door. The question is: is there any benefit to switching doors? The answer surprises many people who haven&rsquo;t heard the question before.</p>

<p>We can answer the problem by running simulations in Python. </p>

<!-- more -->

<p>First, write a function called <code>simulate_prizedoor</code>. Remember to include <code>Numpy</code> library by including at the top <code>import numpy as np</code></p>

<p><code>python
def simulate_prizedoor(nsim):
  return np.random.random_integers(0, high=2, size=nsim)
</code></p>

<p>Next, write a function that simulates the contestant&rsquo;s guesses for <code>nsim</code> simulations. Call this function <code>simulate_guess</code>. This function should be similar to above but we&rsquo;re only testing so we&rsquo;ll just return a bunch of zeros for now:</p>

<p><code>python
def simulate_guess(nsim):
  return np.zeros(nsim, dtype=np.int)
</code></p>

<p>Next, write a function, <code>goat_door</code>, to simulate randomly revealing one of the goat doors that a contestant didn&rsquo;t pick.</p>

<p>```python
def goat_door(prizedoors, guesses):</p>

<pre><code>#strategy: generate random answers, and
#keep updating until they satisfy the rule
#that they aren't a prizedoor or a guess
result = np.random.randint(0, 3, prizedoors.size)
while True:
    bad = (result == prizedoors) | (result == guesses)
    if not bad.any():
        return result
    result[bad] = np.random.randint(0, 3, bad.sum())
</code></pre>

<h1 id="print-goatdoorsimulateprizedoor10-simulateguess10">print goat_door(simulate_prizedoor(10), simulate_guess(10))</h1>
<p>```</p>

<p>Write a function, <code>switch_guess</code>, that represents the strategy of always switching a guess after the goat door is opened. This function is identical in concept to <code>goat_door</code></p>

<p>```python
def switch_guess(guesses, goatdoors):</p>

<pre><code>#strategy: generate random answers, and
#keep updating until they satisfy the rule
#that they aren't the original guess or a goat door
result = np.random.randint(0, 3, guesses.size)
while True:
    bad = (result == guesses) | (result == goatdoors)
    if not bad.any():
        return result
    result[bad] = np.random.randint(0, 3, bad.sum())
</code></pre>

<h1 id="prize--simulateprizedoor10">prize = simulate_prizedoor(10)</h1>
<p>#guess = simulate_guess(10)
#print guess
#print prize
#goat = goat_door(prize, guess)
#print goat
#switch = switch_guess(guess, goat)
#print switch
```</p>

<p>Last function: write a <code>win_percentage</code> function that takes an array of <code>guesses</code> and <code>prizedoors</code>, and returns the percent of correct guesses</p>

<p>```python
def win_percentage(guesses, prizedoors):
    return (guesses == prizedoors).mean()*100</p>

<h1 id="prize--simulateprizedoor10-1">prize = simulate_prizedoor(10)</h1>
<p># guess = simulate_guess(10)
# print guess
# print prize
# win_percentage(guess, prize)
```</p>

<p>Putting it all together. Simulate 10000 games where contestant keeps his original guess, and 10000 games where the contestant switches his door after a  goat door is revealed. Compute the percentage of time the contestant wins under either strategy. Is one strategy better than the other?</p>

<p>```python
nsim = 10000</p>

<h1 id="keep-guesses">keep guesses</h1>
<p>print &ldquo;Win percentage when keeping original door&rdquo;
print win_percentage(simulate_prizedoor(nsim), simulate_guess(nsim))</p>

<h1 id="switch">switch</h1>
<p>pd = simulate_prizedoor(nsim)
guess = simulate_guess(nsim)
goats = goat_door(pd, guess)
guess = switch_guess(guess, goats)
print &ldquo;Win percentage when switching doors&rdquo;
print win_percentage(pd, guess).mean()
```</p>

<p>The result looks something like this:
<code>
Win percentage when keeping original door
32.95
Win percentage when switching doors
66.61
</code></p>

<p>Voila! Always switch!</p>

<p>Additional work: One of the best ways to build intuition about why opening a Goat door affects the odds is to re-run the experiment with 100 doors and one prize. If the game show host opens 98 goat doors after you make your initial selection, would you want to keep your first pick or switch? Can you generalize your simulation code to handle the case of &ldquo;n&rdquo; doors?</p>
]]></content>
  </entry>
  
</feed>
