
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Codex</title>
  <meta name="author" content="Bruno Wu">

  
  <meta name="description" content="In the fourth week at Zipfian, we encountered and implemented a few more basic machine learning algorithms from scratch using Python. One of the more &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://wubr2000.github.io">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/atom.xml" rel="alternate" title="Codex" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="./javascripts/libs/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <!-- MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript"
   src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


<!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=Fjalla+One" rel="stylesheet" type="text/css">
  

</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">Codex</a></h1>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss email">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
    <li><a href="wubr2000@hotmail.com" rel="subscribe-email" title="subscribe via email">Email</a></li>
  
</ul>
  


  <form method="get" action="/search.html">
    <fieldset role="search">
      <input class="search" name="query" type="text" placeholder="Search..." x-webkit-speech />
    </fieldset>
  </form>


<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/portfolio">Portfolio</a></li>
  <li><a href="/about">About</a></li>
  <li><a href="/blog/archives">Archives</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2014/06/07/grow-tree/">How to Grow a (Decision) Tree</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-06-07T23:48:33-07:00" pubdate data-updated="true">Jun 7<span>th</span>, 2014</time>
        
           | <a href="/blog/2014/06/07/grow-tree/#disqus_thread"
             data-disqus-identifier="http://wubr2000.github.io/blog/2014/06/07/grow-tree/">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>In the fourth week at Zipfian, we encountered and implemented a few more basic machine learning algorithms from scratch using Python. One of the more interesting ones for me is the <em>decision tree</em>. The decision tree is quite an appealing classification tool because of its simplicity, effectiveness, and interpretability.</p>

<p>Entropy function:</p>

<script type="math/tex; mode=display">H(y) =  -\displaystyle \sum_{i=1}^{m} P(c_i)\log_2(P(c_i))</script>

</div>
  
  
    <footer>
      <a rel="full-article" href="/blog/2014/06/07/grow-tree/">Read on &rarr;</a>
    </footer>
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2014/05/27/bayesian-invasion/">Gradient Descent the Python Way</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-05-27T22:53:07-07:00" pubdate data-updated="true">May 27<span>th</span>, 2014</time>
        
           | <a href="/blog/2014/05/27/bayesian-invasion/#disqus_thread"
             data-disqus-identifier="http://wubr2000.github.io/blog/2014/05/27/bayesian-invasion/">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>During our third week at Zipfian, we implemented the linear regression model by using various Python libraries (e.g. <code>statsmodel</code> and <code>scikit-learn</code>). We also coded the normal equation (<script type="math/tex">\beta = (X^TX)^{-1}X^TY</script>) directly as a Python function. In addition to using standard library functions to perform linear regressions, we also implemented an optimization technique called <strong><a href="http://en.wikipedia.org/wiki/Gradient_descent">gradient descent</a></strong> to approximate the analytical solution for deriving the coefficients of a linear regression. When a matrix is non-invertible, one would have to use gradient descent to arrive at the coefficients of a linear regression since a <a href="http://stats.stackexchange.com/questions/69442/linear-regression-and-non-invertibility">unique solution does not exist</a> in this case. In fact, gradient descent is a general optimization technique for finding the local minimum of a function and as such, can be applied to many other machine learning situations where an analytical solution is either too cumbersome or is infeasible. So I thought it&rsquo;d be quite useful to get a better handle on this important tool.</p>

<p>Here&rsquo;s the general gradient descent algorithm:</p>

<script type="math/tex; mode=display">
\begin{align*}
  \theta_{j+1} = \theta_j - \alpha \frac{\partial}{\partial\theta_j} J(\theta)
\end{align*}
</script>

<p>where <script type="math/tex">J(\theta)</script> is a function that we want to minimize and <script type="math/tex">\alpha</script> is the <em>learning rate</em>.</p>

</div>
  
  
    <footer>
      <a rel="full-article" href="/blog/2014/05/27/bayesian-invasion/">Read on &rarr;</a>
    </footer>
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/12/29/monty-hall-simulation/">Solving the Monty Hall Problem Using Monte Carlo Simulation</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-12-29T19:25:09-08:00" pubdate data-updated="true">Dec 29<span>th</span>, 2013</time>
        
           | <a href="/blog/2013/12/29/monty-hall-simulation/#disqus_thread"
             data-disqus-identifier="http://wubr2000.github.io/blog/2013/12/29/monty-hall-simulation/">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>This exercise is from <a href="http://cs109.org/">Harvard&rsquo;s CS109 course.</a></p>

<p>In the Monty Hall game show, contestants try to guess which of 3 closed doors contain a cash prize (goats are behind the other two doors). Of course, the odds of choosing the correct door are 1 in 3. As a twist, the host of the show occasionally opens a door after a contestant makes his or her choice. This door is always one of the two the contestant did not pick, and is also always one of the goat doors (note that it is always possible to do this, since there are two goat doors). At this point, the contestant has the option of keeping his or her original choice, or swtiching to the other unopened door. The question is: is there any benefit to switching doors? The answer surprises many people who haven&rsquo;t heard the question before.</p>

<p>We can answer the problem by running simulations in Python. </p>

</div>
  
  
    <footer>
      <a rel="full-article" href="/blog/2013/12/29/monty-hall-simulation/">Read on &rarr;</a>
    </footer>
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/12/29/exploring-nlp-in-python/">Exploring NLP in Python</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-12-29T17:46:50-08:00" pubdate data-updated="true">Dec 29<span>th</span>, 2013</time>
        
           | <a href="/blog/2013/12/29/exploring-nlp-in-python/#disqus_thread"
             data-disqus-identifier="http://wubr2000.github.io/blog/2013/12/29/exploring-nlp-in-python/">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Came across a <a href="http://blog.scripted.com/scripted-updates/nlp-hacking-in-python/">great tutorial</a> on the basics of natural language processing (NLP) and classification. </p>

<p>The example in this tutorial uses a Python library called <code>gensim</code> which (according to its <a href="http://radimrehurek.com/gensim/about.html">website</a>) is the &ldquo;the most robust, efficient and hassle-free piece of software to realize unsupervised semantic modelling from plain text.&rdquo; As far as I understand it, it&rsquo;s a very handy and commonly-used library for NLP.</p>

<p>One important tool/algorithm used for classification is something called the <a href="http://en.wikipedia.org/wiki/Vector_space_model">Vector Space Model</a>. Basically, all documents or queries are represented as &ldquo;vectors of identifiers&rdquo;, such as an index of words and use the angle (theta) between vectors as a similarity measure (explained further later). Incidentally, if you ranked the similarity of each document to a query, you&rsquo;d have a search engine.</p>

</div>
  
  
    <footer>
      <a rel="full-article" href="/blog/2013/12/29/exploring-nlp-in-python/">Read on &rarr;</a>
    </footer>
  


    </article>
  
  <div class="pagination">
    
    <a href="/blog/archives">Blog Archives</a>
    
  </div>
</div>
<aside class="sidebar">
  
    <section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2014/06/07/grow-tree/">How to Grow a (Decision) Tree</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/05/27/bayesian-invasion/">Gradient Descent the Python Way</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/12/29/monty-hall-simulation/">Solving the Monty Hall Problem Using Monte Carlo Simulation</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/12/29/exploring-nlp-in-python/">Exploring NLP in Python</a>
      </li>
    
  </ul>
</section>

<section>
  <h1>GitHub Repos</h1>
  <ul id="gh_repos">
    <li class="loading">Status updating&#8230;</li>
  </ul>
  
  <a href="https://github.com/wubr2000">@wubr2000</a> on GitHub
  
  <script type="text/javascript">
    $(document).ready(function(){
        if (!window.jXHR){
            var jxhr = document.createElement('script');
            jxhr.type = 'text/javascript';
            jxhr.src = '/javascripts/libs/jXHR.js';
            var s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(jxhr, s);
        }

        github.showRepos({
            user: 'wubr2000',
            count: 0,
            skip_forks: true,
            target: '#gh_repos'
        });
    });
  </script>
  <script src="/javascripts/github.js" type="text/javascript"> </script>
</section>





  
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2014 - Bruno Wu -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a> and <a href="https://github.com/vladigleba/readify">Readify</a></span>
</p>

</footer>
  

<script type="text/javascript">
      var disqus_shortname = 'wubr2000';
      
        
        var disqus_script = 'count.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = '//' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>







  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = '//platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
